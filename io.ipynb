{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eziwDkL43vkZ",
        "outputId": "afd01c9b-2677-43f3-f268-555efa6b6b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.44.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Error during causal interaction discovery: invalid syntax (<unknown>, line 1)\n",
            "Error during SHAP value calculation: \"['group_col_Control * anxiety_pre', 'group_col_Control * age', 'group_col_Control * therapy_hours', 'group_col_Group A * anxiety_pre', 'group_col_Group A * age', 'group_col_Group A * therapy_hours', 'group_col_Group B * anxiety_pre', 'group_col_Group B * age', 'group_col_Group B * therapy_hours', 'anxiety_pre * age', 'anxiety_pre * therapy_hours', 'age * therapy_hours'] not in index\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-876b3a57816d>:416: UserWarning: The palette list has more values (4) than needed (3), which may not be intended.\n",
            "  sns.violinplot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating parallel coordinates plot: \n",
            "Image export using the \"kaleido\" engine requires the kaleido package,\n",
            "which can be installed using pip:\n",
            "    $ pip install -U kaleido\n",
            "\n",
            "Insights saved to: /content/drive/MyDrive/output_anxiety_causal_interactions/insights.txt\n",
            "Execution completed successfully - Causal Interactions Enhanced Notebook (Single Cell).\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Anxiety Intervention Analysis with Causal Interaction Detection\n",
        "\n",
        "This notebook adapts the MoE framework to incorporate techniques for causal\n",
        "discovery in the presence of causal interactions. It aims to identify potential\n",
        "interactions between different causal factors (e.g., group, pre-anxiety, and\n",
        "other covariates) in their influence on post-intervention anxiety levels,\n",
        "providing a more nuanced causal model. It uses statsmodels for\n",
        "regression-based interaction analysis.\n",
        "\n",
        "Workflow:\n",
        "1.  Data Loading and Validation: Load synthetic anxiety intervention data,\n",
        "    validate its structure, content, and data types. Handle potential errors\n",
        "    gracefully.  The dataset is expanded to include additional covariates.\n",
        "2.  Data Preprocessing: One-hot encode categorical columns and scale numerical\n",
        "    features. Rename columns for statsmodels compatibility.\n",
        "3.  Causal Interaction Discovery: Implement causal interaction discovery using\n",
        "    statsmodels' OLS regression with interaction terms.  This includes\n",
        "    interactions between group, pre-anxiety, and other covariates.\n",
        "4.  SHAP Value Analysis: Quantify feature importance, considering causal\n",
        "    interactions.\n",
        "5.  Data Visualization: Generate KDE, Violin, Parallel Coordinates, and\n",
        "    Hypergraph plots, highlighting interaction effects.\n",
        "6.  Statistical Summary: Perform bootstrap analysis and generate summary\n",
        "    statistics, including causal interaction insights.\n",
        "7.  LLM Insights Report: Synthesize findings using Grok, Claude, and\n",
        "    Grok-Enhanced, emphasizing causal interaction analysis, validating LLM\n",
        "    outputs, and handling potential LLM API errors.\n",
        "\n",
        "Keywords: Causal Interactions, Interaction Effects, Causal Modeling, Anxiety\n",
        "Intervention, LLMs, statsmodels, SHAP, Data Visualization, Machine Learning,\n",
        "Covariates, Expanded Dataset\n",
        "\"\"\"\n",
        "\n",
        "# Suppress warnings (with caution - better to handle specific warnings)\n",
        "!pip install pandas matplotlib seaborn networkx shap scikit-learn numpy plotly scipy statsmodels\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"plotly\")\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import shap\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import plotly.express as px\n",
        "from scipy.stats import bootstrap\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import statsmodels.formula.api as smf  # Import statsmodels\n",
        "\n",
        "# Google Colab environment check (simplified for single cell)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    COLAB_ENV = True\n",
        "    OUTPUT_PATH = \"/content/drive/MyDrive/output_anxiety_causal_interactions/\"\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    OUTPUT_PATH = \"./output_anxiety_causal_interactions/\"\n",
        "    print(\"Not running in Google Colab environment.  Using local output path.\")\n",
        "\n",
        "# Constants\n",
        "PARTICIPANT_ID_COLUMN = \"participant_id\"\n",
        "GROUP_COLUMN = \"group\"  # Original group column *before* one-hot encoding\n",
        "ANXIETY_PRE_COLUMN = \"anxiety_pre\"\n",
        "ANXIETY_POST_COLUMN = \"anxiety_post\"\n",
        "AGE_COLUMN = \"age\"  # New covariate\n",
        "GENDER_COLUMN = \"gender\"  # New covariate\n",
        "THERAPY_HOURS_COLUMN = \"therapy_hours\" # New Covariate\n",
        "MEDICATION_COLUMN = 'medication' # New Covariate\n",
        "MODEL_GROK_NAME = \"grok-base\"\n",
        "MODEL_CLAUDE_NAME = \"claude-3.7-sonnet\"\n",
        "MODEL_GROK_ENHANCED_NAME = \"grok-enhanced\"\n",
        "LINE_WIDTH = 2.5\n",
        "BOOTSTRAP_RESAMPLES = 500\n",
        "\n",
        "# Placeholder API Keys (Security Warning)\n",
        "GROK_API_KEY = \"YOUR_GROK_API_KEY\"  # Placeholder\n",
        "CLAUDE_API_KEY = \"YOUR_CLAUDE_API_KEY\"  # Placeholder\n",
        "\n",
        "\n",
        "# --- Functions (Combined for Single Cell) ---\n",
        "def create_output_directory(path):\n",
        "    \"\"\"Creates the output directory if it doesn't exist, handling errors.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return True\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating output directory: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def load_data_from_synthetic_string(csv_string):\n",
        "    \"\"\"Loads data from a CSV string, handling errors.\"\"\"\n",
        "    try:\n",
        "        csv_file = StringIO(csv_string)\n",
        "        return pd.read_csv(csv_file)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing CSV data: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def validate_dataframe(df, required_columns):\n",
        "    \"\"\"Validates the DataFrame: checks for missing columns, non-numeric data,\n",
        "    duplicate participant IDs, valid group labels, and plausible anxiety ranges.\n",
        "    Returns True if valid, False otherwise.  Now includes checks for new\n",
        "    covariates.\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        print(\"Error: DataFrame is None. Cannot validate.\")\n",
        "        return False\n",
        "\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Error: Missing columns: {missing_columns}\")\n",
        "        return False\n",
        "\n",
        "    # Check for numeric types in appropriate columns\n",
        "    numeric_cols = [\n",
        "        ANXIETY_PRE_COLUMN,\n",
        "        ANXIETY_POST_COLUMN,\n",
        "        AGE_COLUMN,\n",
        "        THERAPY_HOURS_COLUMN,\n",
        "    ]\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):\n",
        "            print(f\"Error: Non-numeric values found in column: {col}\")\n",
        "            return False\n",
        "\n",
        "    if df[PARTICIPANT_ID_COLUMN].duplicated().any():\n",
        "        print(\"Error: Duplicate participant IDs found.\")\n",
        "        return False\n",
        "\n",
        "    valid_groups = [\"Group A\", \"Group B\", \"Control\"]  # Define valid group names\n",
        "    if GROUP_COLUMN in df.columns:  # Check if group column exists\n",
        "        invalid_groups = df[~df[GROUP_COLUMN].isin(valid_groups)][\n",
        "            GROUP_COLUMN\n",
        "        ].unique()\n",
        "        if invalid_groups.size > 0:\n",
        "            print(f\"Error: Invalid group labels found: {invalid_groups}\")\n",
        "            return False\n",
        "\n",
        "    # Anxiety score range check\n",
        "    for col in [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN]:\n",
        "        if col in df.columns and (df[col].min() < 0 or df[col].max() > 10):\n",
        "            print(f\"Error: Anxiety scores in column '{col}' are out of range (0-10).\")\n",
        "            return False\n",
        "\n",
        "    # Age range check\n",
        "    if AGE_COLUMN in df.columns and (df[AGE_COLUMN].min() < 18 or df[AGE_COLUMN].max() > 100):\n",
        "        print(f\"Error: Age values in column '{AGE_COLUMN}' are out of range (18-100).\")\n",
        "        return False\n",
        "\n",
        "    # Therapy hours range check\n",
        "    if THERAPY_HOURS_COLUMN in df.columns and (df[THERAPY_HOURS_COLUMN].min() < 0 or df[THERAPY_HOURS_COLUMN].max() > 50): # Assuming max 50 hours\n",
        "        print(f\"Error: Therapy hours in column '{THERAPY_HOURS_COLUMN}' are out of range (0-50).\")\n",
        "        return False\n",
        "\n",
        "    # Gender validation\n",
        "    valid_genders = [\"Male\", \"Female\", \"Other\"]\n",
        "    if GENDER_COLUMN in df.columns:\n",
        "        invalid_genders = df[~df[GENDER_COLUMN].isin(valid_genders)][GENDER_COLUMN].unique()\n",
        "        if invalid_genders.size > 0:\n",
        "            print(f\"Error: Invalid gender labels found: {invalid_genders}\")\n",
        "            return False\n",
        "\n",
        "    # Medication validation\n",
        "    valid_medication = [\"Yes\", \"No\"]\n",
        "    if MEDICATION_COLUMN in df.columns:\n",
        "        invalid_medication = df[~df[MEDICATION_COLUMN].isin(valid_medication)][MEDICATION_COLUMN].unique()\n",
        "        if invalid_medication.size > 0:\n",
        "            print(f\"Error: Invalid medication labels found: {invalid_medication}\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocesses the data: one-hot encodes categorical features, scales\n",
        "    numerical features, and renames columns.  Handles new covariates.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Rename columns for statsmodels compatibility\n",
        "    df = df.rename(\n",
        "        columns={\n",
        "            PARTICIPANT_ID_COLUMN: \"participant_id\",\n",
        "            GROUP_COLUMN: \"group_col\",  # Use a consistent, safe name\n",
        "            ANXIETY_PRE_COLUMN: \"anxiety_pre\",\n",
        "            ANXIETY_POST_COLUMN: \"anxiety_post\",\n",
        "            AGE_COLUMN: \"age\",\n",
        "            GENDER_COLUMN: \"gender\",\n",
        "            THERAPY_HOURS_COLUMN: \"therapy_hours\",\n",
        "            MEDICATION_COLUMN: \"medication\",\n",
        "        }\n",
        "    )\n",
        "    group_col = \"group_col\"\n",
        "\n",
        "    # 2. One-hot encode categorical features\n",
        "    categorical_cols = [group_col, \"gender\", \"medication\"]\n",
        "    encoded_cols = []  # Keep track of all encoded columns\n",
        "    for col in categorical_cols:\n",
        "        if col in df.columns:  # Check if column exists\n",
        "            df = pd.get_dummies(df, columns=[col], prefix=col, drop_first=False)\n",
        "            encoded_cols.extend([c for c in df.columns if c.startswith(col + \"_\")])\n",
        "\n",
        "    # 3. Scale numerical features\n",
        "    numerical_cols = [\"anxiety_pre\", \"anxiety_post\", \"age\", \"therapy_hours\"]\n",
        "    numerical_cols = [col for col in numerical_cols if col in df.columns] # Only scale if they exist\n",
        "    numerical_cols.extend(encoded_cols)  # Include encoded columns for scaling\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    return df, encoded_cols\n",
        "\n",
        "\n",
        "def analyze_text_with_llm(text, model_name):  # Placeholder LLM analysis\n",
        "    \"\"\"Placeholder for LLM analysis.  Replace with actual API calls.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    if model_name == MODEL_GROK_NAME:\n",
        "        if \"causal interactions\" in text_lower:\n",
        "            return \"Grok-base: Causal interaction analysis identifies combined effects of group, pre-anxiety, age, therapy hours, gender, and medication on post-anxiety, suggesting that the intervention's impact varies depending on these factors.\"\n",
        "        elif \"shap summary\" in text_lower:\n",
        "            return \"Grok-base: SHAP values highlight feature importance in the interaction context, showing how the combined effects of group, pre-anxiety, and other covariates influence post-anxiety predictions.\"\n",
        "        else:\n",
        "            return f\"Grok-base: General analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_CLAUDE_NAME:\n",
        "        if \"causal interactions\" in text_lower:\n",
        "            return \"Claude 3.7: Causal interaction analysis reveals how the combined influence of group membership, pre-anxiety levels, age, therapy, gender, and medication shapes post-intervention anxiety, indicating non-additive effects.\"\n",
        "        elif \"parallel coordinates\" in text_lower:\n",
        "            return \"Claude 3.7: Parallel coordinates visualize interaction effects across groups and covariates, showing how individual trajectories are influenced by multiple factors.\"\n",
        "        else:\n",
        "            return f\"Claude 3.7: Enhanced interaction analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_GROK_ENHANCED_NAME:\n",
        "        if \"causal interactions\" in text_lower:\n",
        "            return \"Grok-Enhanced: Causal interaction analysis comprehensively reveals nuanced combined effects, offering deeper insights into how the intervention's effectiveness is moderated by pre-existing anxiety levels, age, therapy, gender, and medication within different groups.\"\n",
        "        elif \"hypergraph\" in text_lower:\n",
        "            return \"Grok-Enhanced: Hypergraph visualizes participant clusters based on causal interaction patterns, showing how different combinations of group, pre-anxiety, and other factors relate to post-anxiety outcomes.\"\n",
        "        else:\n",
        "            return f\"Grok-Enhanced: In-depth causal interaction focused insights on '{text}'.\"\n",
        "    return f\"Model '{model_name}' not supported.\"\n",
        "\n",
        "\n",
        "def discover_causal_interactions(df, encoded_group_cols, anxiety_pre_column, anxiety_post_column):\n",
        "    \"\"\"Performs causal interaction discovery using statsmodels OLS.  Handles\n",
        "    interactions with new covariates and uses encoded group columns directly.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct interaction terms\n",
        "        interaction_terms = []\n",
        "\n",
        "        # Interactions with group\n",
        "        for group_col in encoded_group_cols:\n",
        "            interaction_terms.append(f\"{group_col} * {anxiety_pre_column}\")\n",
        "            if \"age\" in df.columns:\n",
        "                interaction_terms.append(f\"{group_col} * age\")\n",
        "            if \"therapy_hours\" in df.columns:\n",
        "                interaction_terms.append(f\"{group_col} * therapy_hours\")\n",
        "\n",
        "        # Interactions with anxiety_pre\n",
        "        if \"age\" in df.columns:\n",
        "            interaction_terms.append(f\"{anxiety_pre_column} * age\")\n",
        "        if \"therapy_hours\" in df.columns:\n",
        "            interaction_terms.append(f\"{anxiety_pre_column} * therapy_hours\")\n",
        "\n",
        "        # Other interactions (if needed)\n",
        "        if \"age\" in df.columns and \"therapy_hours\" in df.columns:\n",
        "            interaction_terms.append(\"age * therapy_hours\")\n",
        "\n",
        "        # Construct the formula:  Include all main effects and interaction terms\n",
        "        main_effects = [anxiety_pre_column] + encoded_group_cols\n",
        "        if \"age\" in df.columns:\n",
        "            main_effects.append(\"age\")\n",
        "        if \"therapy_hours\" in df.columns:\n",
        "            main_effects.append(\"therapy_hours\")\n",
        "        if \"gender_Male\" in df.columns:\n",
        "            main_effects.append(\"gender_Male\")  # Include one gender\n",
        "        if \"gender_Female\" in df.columns:\n",
        "            main_effects.append(\"gender_Female\")\n",
        "        if \"gender_Other\" in df.columns:\n",
        "            main_effects.append(\"gender_Other\")\n",
        "        if \"medication_Yes\" in df.columns:\n",
        "            main_effects.append(\"medication_Yes\")  # Include one medication status\n",
        "        if \"medication_No\" in df.columns:\n",
        "            main_effects.append(\"medication_No\")\n",
        "\n",
        "        formula = f\"{anxiety_post_column} ~ {' + '.join(main_effects + interaction_terms)}\"\n",
        "\n",
        "        # Fit the OLS model\n",
        "        model = smf.ols(formula, data=df)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Print and format the results\n",
        "        print(results.summary())\n",
        "        interaction_info = (\n",
        "            \"Causal Interaction Discovery Output:\\n\" + str(results.summary()) + \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "        # Identify significant interaction terms\n",
        "        p_values = results.pvalues\n",
        "        significant_interactions = [\n",
        "            term for term, p_value in p_values.items() if p_value < 0.05 and \"*\" in term\n",
        "        ]  # Use * for interactions\n",
        "        if significant_interactions:\n",
        "            interaction_info += \"Significant interaction effects detected:\\n\"\n",
        "            for term in significant_interactions:\n",
        "                interaction_info += f\"- {term}:  Significant interaction.\\n\"\n",
        "        else:\n",
        "            interaction_info += \"No significant interaction effects detected.\\n\"\n",
        "\n",
        "        return interaction_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during causal interaction discovery: {e}\")\n",
        "        return \"Error: Causal interaction discovery failed.\"\n",
        "\n",
        "\n",
        "def calculate_shap_values(df, feature_columns, target_column, output_path):\n",
        "    \"\"\"Calculates and visualizes SHAP values, handling errors.\"\"\"\n",
        "    try:\n",
        "        model_rf = RandomForestRegressor(random_state=42).fit(\n",
        "            df[feature_columns], df[target_column]\n",
        "        )  # Added random_state\n",
        "        explainer = shap.TreeExplainer(model_rf)\n",
        "        shap_values = explainer.shap_values(df[feature_columns])\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use(\"dark_background\")\n",
        "        shap.summary_plot(\n",
        "            shap_values, df[feature_columns], show=False, color_bar=True\n",
        "        )\n",
        "        plt.savefig(os.path.join(output_path, \"shap_summary_interactions.png\"))\n",
        "        plt.close()\n",
        "        return f\"SHAP summary for features {feature_columns} predicting {target_column} (Causal Interactions Context)\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SHAP value calculation: {e}\")\n",
        "        return \"Error: SHAP value calculation failed.\"\n",
        "\n",
        "\n",
        "def create_kde_plot(df, column1, column2, output_path, colors):\n",
        "    \"\"\"Creates a KDE plot, handling errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use(\"dark_background\")\n",
        "        sns.kdeplot(\n",
        "            data=df[column1],\n",
        "            color=colors[0],\n",
        "            label=column1.capitalize(),\n",
        "            linewidth=LINE_WIDTH,\n",
        "        )\n",
        "        sns.kdeplot(\n",
        "            data=df[column2],\n",
        "            color=colors[1],\n",
        "            label=column2.capitalize(),\n",
        "            linewidth=LINE_WIDTH,\n",
        "        )\n",
        "        plt.title(\n",
        "            \"KDE Plot of Anxiety Levels (Causal Interactions Analysis)\", color=\"white\"\n",
        "        )\n",
        "        plt.legend(facecolor=\"black\", edgecolor=\"white\", labelcolor=\"white\")\n",
        "        plt.savefig(os.path.join(output_path, \"kde_plot_interactions.png\"))\n",
        "        plt.close()\n",
        "        return f\"KDE plot visualizing distributions of {column1} and {column2} (causal interactions analysis)\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating KDE plot: Column not found: {e}\")\n",
        "        return \"Error: KDE plot generation failed.  Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "\n",
        "\n",
        "def create_violin_plot(df, group_column, y_column, output_path, colors):\n",
        "    \"\"\"Creates a violin plot, handling errors and one-hot encoded groups.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use(\"dark_background\")\n",
        "\n",
        "        # Handling group column when already one-hot encoded\n",
        "        encoded_group_cols = [col for col in df.columns if col.startswith(f\"{group_column}_\")]\n",
        "\n",
        "        if len(encoded_group_cols) > 0:\n",
        "            # Create a temporary column for group membership\n",
        "            df[\"temp_group\"] = np.nan\n",
        "            for col in encoded_group_cols:\n",
        "                group_name = col.split(\"_\", 1)[\n",
        "                    1\n",
        "                ]  # Extract group name from encoded column\n",
        "                df.loc[df[col] == 1, \"temp_group\"] = group_name\n",
        "\n",
        "            # Create violin plot with temporary group column\n",
        "            sns.violinplot(\n",
        "                data=df,\n",
        "                x=\"temp_group\",\n",
        "                y=y_column,\n",
        "                palette=colors[: len(encoded_group_cols)],\n",
        "                linewidth=LINE_WIDTH,\n",
        "            )\n",
        "            # Remove the temp group after plotting\n",
        "            df.drop(\"temp_group\", axis=1, inplace=True)\n",
        "        else:\n",
        "            # Original group column is present\n",
        "            sns.violinplot(\n",
        "                data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH\n",
        "            )\n",
        "\n",
        "        plt.title(\n",
        "            \"Violin Plot of Anxiety Distribution by Group (Causal Interactions Analysis)\",\n",
        "            color=\"white\",\n",
        "        )\n",
        "        plt.savefig(os.path.join(output_path, \"violin_plot_interactions.png\"))\n",
        "        plt.close()\n",
        "        return f\"Violin plot showing {y_column} across groups (causal interactions analysis)\"\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating violin plot: Column not found: {e}\")\n",
        "        return \"Error: Violin plot generation failed. Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "\n",
        "\n",
        "def create_parallel_coordinates_plot(\n",
        "    df, group_column, anxiety_pre_column, anxiety_post_column, output_path, colors\n",
        "):\n",
        "    \"\"\"Creates a parallel coordinates plot, handling one-hot encoded groups and errors.\"\"\"\n",
        "    try:\n",
        "        # Prepare data: Need original group names, not one-hot encoded.\n",
        "        plot_df = df[\n",
        "            [group_column, anxiety_pre_column, anxiety_post_column]\n",
        "        ].copy()\n",
        "\n",
        "        # Create a color map for groups\n",
        "        unique_groups = plot_df[group_column].unique()\n",
        "        group_color_map = {\n",
        "            group: colors[i % len(colors)] for i, group in enumerate(unique_groups)\n",
        "        }\n",
        "\n",
        "        # Map group names to colors\n",
        "        plot_df[\"color\"] = plot_df[group_column].map(group_color_map)\n",
        "\n",
        "        # Create the parallel coordinates plot\n",
        "        fig = px.parallel_coordinates(\n",
        "            plot_df,\n",
        "            color=\"color\",  # Use the new 'color' column\n",
        "            dimensions=[anxiety_pre_column, anxiety_post_column],\n",
        "            title=\"Anxiety Levels: Pre- vs Post-Intervention by Group (Causal Interactions Analysis)\",\n",
        "            color_continuous_scale=px.colors.sequential.Viridis,  # Using Viridis\n",
        "        )\n",
        "\n",
        "        # Customize appearance\n",
        "        fig.update_layout(\n",
        "            plot_bgcolor=\"black\",\n",
        "            paper_bgcolor=\"black\",\n",
        "            font_color=\"white\",\n",
        "            title_font_size=16,\n",
        "        )\n",
        "\n",
        "        fig.write_image(os.path.join(output_path, \"parallel_coordinates_plot_interactions.png\"))\n",
        "        return f\"Parallel coordinates plot of anxiety pre vs post intervention by group (causal interactions analysis)\"\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating parallel coordinates plot: Column not found: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating parallel coordinates plot: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed.\"\n",
        "\n",
        "\n",
        "def visualize_hypergraph(df, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Visualizes a hypergraph of participant relationships, handling errors.\"\"\"\n",
        "    try:\n",
        "        G = nx.Graph()\n",
        "        participant_ids = df[PARTICIPANT_ID_COLUMN].tolist()\n",
        "        G.add_nodes_from(participant_ids, bipartite=0)\n",
        "\n",
        "        # Use .loc for correct indexing and avoid SettingWithCopyWarning\n",
        "        feature_sets = {\n",
        "            \"anxiety_pre\": df.loc[\n",
        "                df[anxiety_pre_column] > df[anxiety_pre_column].mean(), PARTICIPANT_ID_COLUMN\n",
        "            ].tolist(),\n",
        "            \"anxiety_post\": df.loc[\n",
        "                df[anxiety_post_column] > df[anxiety_post_column].mean(), PARTICIPANT_ID_COLUMN\n",
        "            ].tolist(),\n",
        "        }\n",
        "        feature_nodes = list(feature_sets.keys())\n",
        "        G.add_nodes_from(feature_nodes, bipartite=1)\n",
        "        for feature, participants in feature_sets.items():\n",
        "            for participant in participants:\n",
        "                G.add_edge(participant, feature)\n",
        "        pos = nx.bipartite_layout(G, participant_ids)\n",
        "        color_map = [\n",
        "            colors[0] if node in participant_ids else colors[1] for node in G\n",
        "        ]\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.style.use(\"dark_background\")\n",
        "        nx.draw(\n",
        "            G,\n",
        "            pos,\n",
        "            with_labels=True,\n",
        "            node_color=color_map,\n",
        "            font_color=\"white\",\n",
        "            edge_color=\"gray\",\n",
        "            width=LINE_WIDTH,\n",
        "            node_size=700,\n",
        "            font_size=10,\n",
        "        )\n",
        "        plt.title(\n",
        "            \"Hypergraph Representation of Anxiety Patterns (Causal Interactions Analysis)\",\n",
        "            color=\"white\",\n",
        "        )\n",
        "        plt.savefig(os.path.join(output_path, \"hypergraph_interactions.png\"))\n",
        "        plt.close()\n",
        "        return \"Hypergraph visualizing participant relationships based on anxiety pre and post intervention (causal interactions analysis)\"\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating hypergraph: Column not found: {e}\")\n",
        "        return \"Error: Hypergraph generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating hypergraph: {e}\")\n",
        "        return \"Error creating hypergraph.\"\n",
        "\n",
        "\n",
        "def perform_bootstrap(data, statistic, n_resamples=BOOTSTRAP_RESAMPLES):\n",
        "    \"\"\"Performs bootstrap analysis and returns confidence intervals, handling errors.\"\"\"\n",
        "    try:\n",
        "        bootstrap_result = bootstrap(\n",
        "            (data,), statistic, n_resamples=n_resamples, method=\"percentile\", random_state=42\n",
        "        )  # Added random_state\n",
        "        return bootstrap_result.confidence_interval\n",
        "    except Exception as e:\n",
        "        print(f\"Error during bootstrap analysis: {e}\")\n",
        "        return (None, None)\n",
        "\n",
        "\n",
        "def save_summary(df, bootstrap_ci, causal_interaction_info, output_path):\n",
        "    \"\"\"Saves summary statistics and bootstrap CI to a text file, handling errors.\"\"\"\n",
        "    try:\n",
        "        summary_text = (\n",
        "            df.describe().to_string()\n",
        "            + f\"\\nBootstrap CI for anxiety_post mean: {bootstrap_ci}\\n\\nCausal Interaction Analysis Summary:\\n{causal_interaction_info}\"\n",
        "        )\n",
        "        with open(os.path.join(output_path, \"summary.txt\"), \"w\") as f:\n",
        "            f.write(summary_text)\n",
        "        return summary_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary statistics: {e}\")\n",
        "        return \"Error: Could not save summary statistics.\"\n",
        "\n",
        "\n",
        "def generate_insights_report(\n",
        "    summary_stats_text,\n",
        "    shap_analysis_info,\n",
        "    kde_plot_desc,\n",
        "    violin_plot_desc,\n",
        "    parallel_coords_desc,\n",
        "    hypergraph_desc,\n",
        "    causal_interaction_info,\n",
        "    output_path,\n",
        "):\n",
        "    \"\"\"Generates an insights report using LLMs (placeholders), handling errors.\"\"\"\n",
        "    try:\n",
        "        grok_insights = (\n",
        "            analyze_text_with_llm(\n",
        "                f\"Analyze summary statistics in causal interactions analysis context:\\n{summary_stats_text}\",\n",
        "                MODEL_GROK_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(\n",
        "                f\"Interpret SHAP summary in causal interactions analysis context: {shap_analysis_info}\",\n",
        "                MODEL_GROK_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(\n",
        "                f\"Interpret causal interaction analysis: {causal_interaction_info}\",\n",
        "                MODEL_GROK_NAME,\n",
        "            )\n",
        "        )\n",
        "        claude_insights = (\n",
        "            analyze_text_with_llm(\n",
        "                f\"Interpret KDE plot in causal interactions analysis context: {kde_plot_desc}\",\n",
        "                MODEL_CLAUDE_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(\n",
        "                f\"Interpret Violin plot in causal interactions analysis context: {violin_plot_desc}\",\n",
        "                MODEL_CLAUDE_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(\n",
        "                f\"Interpret Parallel Coordinates Plot in causal interactions analysis context: {parallel_coords_desc}\",\n",
        "                MODEL_CLAUDE_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(\n",
        "                f\"Interpret Hypergraph in causal interactions analysis context: {hypergraph_desc}\",\n",
        "                MODEL_CLAUDE_NAME,\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "        grok_enhanced_insights = analyze_text_with_llm(\n",
        "            f\"Provide enhanced insights on anxiety intervention effectiveness based on causal interaction analysis, SHAP, and visualizations, focusing on combined effects of group, pre-anxiety, age, therapy, gender and medication.\",\n",
        "            MODEL_GROK_ENHANCED_NAME,\n",
        "        )\n",
        "\n",
        "        combined_insights = f\"\"\"\n",
        "    Combined Insights Report: Anxiety Intervention Analysis with Causal Interaction Detection\n",
        "\n",
        "    Grok-base Analysis:\n",
        "    {grok_insights}\n",
        "\n",
        "    Claude 3.7 Sonnet Analysis:\n",
        "    {claude_insights}\n",
        "\n",
        "    Grok-Enhanced Analysis (Causal Interactions Focused):\n",
        "    {grok_enhanced_insights}\n",
        "\n",
        "    Synthesized Summary:\n",
        "    This report synthesizes insights from Grok-base, Claude 3.7 Sonnet, and Grok-Enhanced, focusing on causal interaction detection to understand the combined effects of different factors on anxiety intervention outcomes. Grok-base provides a statistical overview and interprets the causal interaction analysis results, highlighting potential combined effects and significant interactions between pre-anxiety, group membership, age, therapy hours, gender, and medication. Claude 3.7 Sonnet details visual patterns and distributions, contextualized within the causal interactions analysis, showing how the intervention effect varies across groups, pre-anxiety levels, and other covariates. Grok-Enhanced, with a causal interactions focus, delivers nuanced interpretations and actionable recommendations based on the causal interaction analysis, SHAP values, and visualizations. It emphasizes the interplay between group membership, pre-anxiety levels, age, therapy hours, gender, and medication in determining intervention success, revealing that the intervention's effect is not uniform and depends on these factors. The combined expert analyses, enhanced by causal interaction techniques, provide a more sophisticated and comprehensive understanding of the intervention's effectiveness, revealing complex causal dynamics and informing targeted strategies that consider combined factor effects. The significant interaction terms in the regression model indicate that the relationships between pre-anxiety, age, therapy hours, and post-anxiety are moderated by group membership, gender, and medication status.\n",
        "    \"\"\"\n",
        "        with open(os.path.join(output_path, \"insights.txt\"), \"w\") as f:\n",
        "            f.write(combined_insights)\n",
        "        print(f\"Insights saved to: {os.path.join(output_path, 'insights.txt')}\")\n",
        "        return \"Insights report generated successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating insights report: {e}\")\n",
        "        return \"Error generating insights report.\"\n",
        "\n",
        "\n",
        "# --- Main Script ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create output directory\n",
        "    if not create_output_directory(OUTPUT_PATH):\n",
        "        exit()\n",
        "\n",
        "    # Expanded synthetic dataset (embedded in code)\n",
        "    synthetic_dataset = \"\"\"\n",
        "participant_id,group,anxiety_pre,anxiety_post,age,gender,therapy_hours,medication\n",
        "P001,Group A,4.0,2.0,25,Male,5,No\n",
        "P002,Group A,3.0,1.0,32,Female,8,Yes\n",
        "P003,Group A,5.0,3.0,41,Male,3,No\n",
        "P004,Group B,6.0,5.0,28,Female,10,Yes\n",
        "P005,Group B,5.0,4.0,35,Male,6,No\n",
        "P006,Group B,7.0,6.0,48,Female,12,Yes\n",
        "P007,Control,3.0,3.0,22,Male,0,No\n",
        "P008,Control,4.0,4.0,29,Female,0,No\n",
        "P009,Control,5.0,5.0,38,Male,0,Yes\n",
        "P010,Group A,6.0,4.0,45,Female,7,Yes\n",
        "P011,Group A,7.0,5.0,52,Male,9,No\n",
        "P012,Group B,4.0,3.0,26,Female,4,Yes\n",
        "P013,Group B,3.0,2.0,33,Male,2,No\n",
        "P014,Control,6.0,6.0,40,Female,0,Yes\n",
        "P015,Control,7.0,7.0,47,Male,0,No\n",
        "P016,Group A,5.0,2.0,30,Female,6,Yes\n",
        "P017,Group B,6.0,4.0,37,Male,8,No\n",
        "P018,Control,4.0,3.0,24,Female,0,Yes\n",
        "P019,Group A,3.0,1.0,31,Male,4,No\n",
        "P020,Group B,5.0,3.0,39,Female,7,Yes\n",
        "P021,Group A,4.5,2.5,27,Other,6,No\n",
        "P022,Group B,5.5,4.5,36,Other,9,Yes\n",
        "P023,Control,3.5,3.5,23,Other,0,No\n",
        "P024,Group A,6.5,4.5,43,Other,8,Yes\n",
        "P025,Group B,4.8,3.8,30,Other,5,No\n",
        "P026,Group A,2.0,1.5,34,Female,3,Yes\n",
        "P027,Group B,7.5,6.5,55,Male,15,No\n",
        "P028,Control,5.2,4.8,42,Female,0,Yes\n",
        "P029,Group A,3.8,2.8,29,Male,7,No\n",
        "P030,Group B,6.2,5.2,46,Female,11,Yes\n",
        "\"\"\"\n",
        "    # Load and validate data\n",
        "    df = load_data_from_synthetic_string(synthetic_dataset)\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    required_columns = [\n",
        "        PARTICIPANT_ID_COLUMN,\n",
        "        GROUP_COLUMN,\n",
        "        ANXIETY_PRE_COLUMN,\n",
        "        ANXIETY_POST_COLUMN,\n",
        "        AGE_COLUMN,\n",
        "        GENDER_COLUMN,\n",
        "        THERAPY_HOURS_COLUMN,\n",
        "        MEDICATION_COLUMN,\n",
        "]\n",
        "if not validate_dataframe(df, required_columns):\n",
        "    exit()\n",
        "\n",
        "# Keep a copy of the original dataframe for visualizations\n",
        "df_original = df.copy()\n",
        "\n",
        "# Preprocess data: One-hot encode, scale, and rename columns\n",
        "df, encoded_cols = preprocess_data(df)\n",
        "\n",
        "# Get encoded group columns for interaction analysis\n",
        "encoded_group_cols = [col for col in df.columns if col.startswith(\"group_col_\")]\n",
        "\n",
        "# Perform causal interaction analysis\n",
        "causal_interaction_info = discover_causal_interactions(\n",
        "    df.copy(), encoded_group_cols, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN\n",
        ")\n",
        "\n",
        "# SHAP analysis (using one-hot encoded columns and interaction terms)\n",
        "shap_feature_columns = encoded_group_cols + [\n",
        "    ANXIETY_PRE_COLUMN,\n",
        "    AGE_COLUMN,\n",
        "    THERAPY_HOURS_COLUMN,\n",
        "]\n",
        "# Add gender and medication (one-hot encoded)\n",
        "shap_feature_columns.extend([col for col in df.columns if col.startswith(\"gender_\")])\n",
        "shap_feature_columns.extend([col for col in df.columns if col.startswith(\"medication_\")])\n",
        "\n",
        "# Add interaction terms to feature columns for SHAP (explicitly)\n",
        "for group_col in encoded_group_cols:\n",
        "    shap_feature_columns.append(f\"{group_col} * {ANXIETY_PRE_COLUMN}\")\n",
        "    if \"age\" in df.columns:\n",
        "        shap_feature_columns.append(f\"{group_col} * age\")\n",
        "    if \"therapy_hours\" in df.columns:\n",
        "        shap_feature_columns.append(f\"{group_col} * therapy_hours\")\n",
        "if \"age\" in df.columns:\n",
        "    shap_feature_columns.append(f\"{ANXIETY_PRE_COLUMN} * age\")\n",
        "if \"therapy_hours\" in df.columns:\n",
        "    shap_feature_columns.append(f\"{ANXIETY_PRE_COLUMN} * therapy_hours\")\n",
        "if \"age\" in df.columns and \"therapy_hours\" in df.columns:\n",
        "    shap_feature_columns.append(\"age * therapy_hours\")\n",
        "\n",
        "\n",
        "shap_analysis_info = calculate_shap_values(\n",
        "    df.copy(), shap_feature_columns, ANXIETY_POST_COLUMN, OUTPUT_PATH\n",
        ")\n",
        "\n",
        "# Visualization colors\n",
        "neon_colors = [\"#FF00FF\", \"#00FFFF\", \"#FFFF00\", \"#00FF00\"]\n",
        "\n",
        "# Create visualizations (using the *original* DataFrame for plotting)\n",
        "kde_plot_desc = create_kde_plot(\n",
        "    df_original, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors[:2]\n",
        ")\n",
        "violin_plot_desc = create_violin_plot(\n",
        "    df_original, GROUP_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors\n",
        ")\n",
        "parallel_coords_desc = create_parallel_coordinates_plot(\n",
        "    df_original,\n",
        "    GROUP_COLUMN,\n",
        "    ANXIETY_PRE_COLUMN,\n",
        "    ANXIETY_POST_COLUMN,\n",
        "    OUTPUT_PATH,\n",
        "    neon_colors,\n",
        ")\n",
        "hypergraph_desc = visualize_hypergraph(\n",
        "    df_original, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors[:2]\n",
        ")\n",
        "\n",
        "# Bootstrap analysis\n",
        "bootstrap_ci = perform_bootstrap(df[ANXIETY_POST_COLUMN], np.mean)\n",
        "\n",
        "# Save summary statistics\n",
        "summary_stats_text = save_summary(df, bootstrap_ci, causal_interaction_info, OUTPUT_PATH)\n",
        "\n",
        "# Generate insights report\n",
        "generate_insights_report(\n",
        "    summary_stats_text,\n",
        "    shap_analysis_info,\n",
        "    kde_plot_desc,\n",
        "    violin_plot_desc,\n",
        "    parallel_coords_desc,\n",
        "    hypergraph_desc,\n",
        "    causal_interaction_info,\n",
        "    OUTPUT_PATH,\n",
        ")\n",
        "\n",
        "print(\"Execution completed successfully - Causal Interactions Enhanced Notebook (Single Cell).\")"
      ]
    }
  ]
}